{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from statistics import mean, stdev\n",
    "import math\n",
    "\n",
    "from retrofitting_funcs import get_embs, get_retro_embs\n",
    "\n",
    "#extract nouns, verbs and adjectives \n",
    "os.chdir('/nfs/gpusan01/gbihani/context_div/WSD_data/mydata/')\n",
    "\n",
    "with open('nouns.pkl', 'rb') as f:\n",
    "    nouns = pickle.load(f)\n",
    "    \n",
    "with open('verbs.pkl', 'rb') as f:\n",
    "    verbs = pickle.load(f)\n",
    "    \n",
    "with open('adjectives.pkl', 'rb') as f:\n",
    "    adjectives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an embedding file for (model: 'bert', layer: 0, dataset: 'semeval15_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= get_embs('semeval15_13', 0, 'bert') #get original embeddings\n",
    "van = [((y[0][0], y[0][1], y[0][2]), y[1]) for x in data for y in x]\n",
    "van_vec = [x[1] for x in van]\n",
    "vans_ = van\n",
    "\n",
    "##final file to be used is vans_filt\n",
    "vans_filt_ = [x for x in vans_ if ((x[0][1] in [y1[0] for y1 in nouns]) or (x[0][1] in [y2[0] for y2 in verbs]) or\n",
    "                                     (x[0][1] in [y3[0] for y3 in adjectives]))] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 'document', 'document%1:10:00::'),\n",
       " tensor([ 0.1707,  0.1397, -0.7813,  0.1900, -0.0214, -0.2148,  0.2324, -1.0346,\n",
       "          0.6158, -1.1655, -0.5458,  0.1694, -0.2444,  0.9020,  0.3099, -0.6317,\n",
       "          0.3262,  0.7722,  0.0199,  0.0187,  0.4702, -1.0844, -0.4344, -0.1920,\n",
       "          0.5877, -0.3990, -0.5780, -0.0775,  0.6177, -1.0305, -0.0022,  0.3859,\n",
       "          0.7303, -0.7913,  0.1190, -0.1364,  0.0713,  0.4134, -1.2910,  0.9592,\n",
       "          0.4427, -0.4876, -1.0003,  0.1014, -0.4867,  0.2853, -0.3453,  0.7880,\n",
       "          0.5581,  0.5480,  0.2823, -0.0076, -0.9888,  0.8198,  0.1645, -0.1814,\n",
       "         -0.1852,  0.3802,  0.6396, -0.8974,  0.9390,  0.8562,  0.0986, -0.1087,\n",
       "         -0.2598, -0.6736, -0.0488, -0.9092,  0.6115,  0.1314,  0.2512,  1.0240,\n",
       "         -0.3224, -0.1817,  0.2863, -1.4376,  0.7122,  0.8311,  0.1375,  0.3231,\n",
       "          0.1430,  1.1465, -0.4424,  0.5618, -0.1055,  0.1053,  0.5605,  0.7176,\n",
       "         -0.4838,  0.5024,  0.7018, -0.6256, -0.6824,  0.2438,  0.1221, -0.5718,\n",
       "         -0.0529, -0.8547,  0.0176, -0.1036,  0.0174, -0.4563,  1.2640, -0.2784,\n",
       "         -0.5983,  0.5913, -0.5713, -0.0506, -1.2175,  0.6145, -0.3452,  0.3913,\n",
       "         -0.8318, -0.1316,  1.3565,  0.1406,  0.5453, -0.4440,  0.6352,  0.3951,\n",
       "          0.1633,  0.4687,  0.3314, -0.7355, -0.2449, -0.5482,  0.3094,  0.3325,\n",
       "          0.0864, -1.1670,  0.9686,  0.5508, -0.0622, -0.2553,  0.3646,  0.2845,\n",
       "          0.3245, -0.1921,  0.0072, -0.9909, -0.4930,  0.8018,  0.5369, -0.0596,\n",
       "         -0.5643,  0.0690,  0.1591,  0.2714, -0.0310, -0.7753,  0.9771,  0.2380,\n",
       "          0.4006,  0.0366,  0.0933,  0.6863, -0.3340, -0.8834,  0.6348,  0.7009,\n",
       "          1.2076,  0.7358,  0.1299,  0.2415,  0.4924,  0.9105,  0.1805,  0.3128,\n",
       "         -1.3977, -0.3030,  0.6226,  0.7816, -0.4812, -0.4237,  0.1935, -0.1308,\n",
       "          0.0058, -0.1202, -0.5980, -0.4219,  1.0235,  0.7226,  0.0969, -0.5184,\n",
       "         -0.0218,  0.9215, -0.1175,  0.2231, -0.3314, -0.4948,  0.2317, -0.5823,\n",
       "          0.8900, -0.5317,  0.1502,  0.4459, -0.3759, -1.2757, -1.5539, -0.4269,\n",
       "         -0.6147,  0.4183,  0.3848, -0.0214, -0.5189,  0.6628, -0.1912, -0.0374,\n",
       "          0.2124,  0.5114, -0.3910,  0.2959,  0.8102,  0.2530, -0.8827,  0.3645,\n",
       "         -0.4456, -0.9123,  0.8495, -0.3289, -0.3961, -0.2034,  0.6686, -0.2092,\n",
       "          0.3355, -0.0903,  0.1730,  0.0824,  0.3278, -0.2534, -0.0127,  0.0862,\n",
       "         -0.6778, -0.8491,  0.2499, -1.3372, -0.7014,  0.2515, -0.7269, -0.0540,\n",
       "          0.2686, -0.9022, -0.2352,  0.0593, -1.0340,  0.8904,  0.2424, -0.4713,\n",
       "         -0.0408, -1.2072,  1.0039,  0.1979,  0.6057, -0.0660,  1.0538, -1.0997,\n",
       "         -0.4337, -0.1821,  0.1624, -0.3151,  0.4159, -0.3141,  0.7812,  0.0685,\n",
       "         -0.5254,  0.4495, -0.6372,  0.4398,  0.0876, -0.0734, -0.5530, -0.7230,\n",
       "          0.2720, -0.2267, -0.4188, -0.7049,  0.6877,  0.1163, -0.9438,  0.6031,\n",
       "         -0.2909, -1.1592,  0.5478, -0.3298,  0.3528, -0.3958, -0.0655,  0.4826,\n",
       "          0.2603,  0.5269,  0.2683,  0.9726, -0.6152,  0.2675, -0.2898,  0.0532,\n",
       "          0.4110, -0.5298, -1.7215,  0.2067,  0.4324,  0.1820,  0.2322,  0.0862,\n",
       "          0.1919, -1.2126,  0.2144, -0.5688,  0.0508, -0.5531, -0.6356,  0.0686,\n",
       "          0.7513,  0.0918, -0.7233, -1.1734, -0.0897, -0.3030, -0.4986,  0.2851,\n",
       "          0.4572,  0.0186, -0.4965,  0.2826,  0.5766, -1.2572, -0.1032,  0.5553,\n",
       "          0.7553,  1.1921, -0.0854,  0.4129,  0.7575, -0.4533,  0.2009, -0.6256,\n",
       "         -0.0555,  0.7514,  0.1438, -0.7163, -0.2453,  1.0132, -0.7262, -0.8820,\n",
       "         -0.4583, -0.3505, -0.3567, -0.5282, -0.2331, -0.6170,  0.2548, -0.3582,\n",
       "          0.1750,  0.9634,  0.3659, -0.5550,  0.6102, -0.0690, -0.1190,  0.6971,\n",
       "         -0.3318, -0.5980, -0.1876,  0.3135,  0.0096,  0.4904, -0.5573, -0.3409,\n",
       "          0.2513,  0.2636,  0.7039, -0.0246, -0.0453, -0.1924,  0.8254, -0.2395,\n",
       "          0.1692, -0.7921, -0.2082,  0.0693, -0.6131,  0.2022,  0.5757,  0.1321,\n",
       "         -0.4725,  0.1344, -0.6566, -1.0005, -0.5217,  0.8024,  1.4571,  0.6039,\n",
       "         -0.5013,  0.3177,  0.4096,  0.0355, -0.5700, -0.2727,  0.2113, -0.1584,\n",
       "          0.4021, -0.1299, -0.5852,  0.2449, -0.8147,  0.4869, -1.0284,  0.5797,\n",
       "          0.5151,  0.0863,  0.2354,  0.3936, -0.3866,  0.2936, -0.5301, -0.7423,\n",
       "          0.7051, -1.0218, -0.3542, -0.0161, -0.6048, -0.1984, -0.0547,  0.0046,\n",
       "          0.1982,  0.8015,  0.1098, -0.3650,  0.7175, -0.9911, -0.3586,  0.4481,\n",
       "          0.5965,  0.1451,  0.2343,  0.3496, -0.3705, -0.5005, -1.0584, -0.5619,\n",
       "         -1.8080, -0.2338, -0.0240,  0.6938, -0.4128, -0.2710,  0.7534, -0.0335,\n",
       "          0.9217,  0.2692,  0.3445,  0.5118, -1.4380,  0.0715,  0.2829,  1.1728,\n",
       "         -0.2126, -1.0534,  0.3040,  1.5753, -0.3194, -0.0402, -0.4299,  0.0359,\n",
       "         -0.7172, -0.3018,  0.2467,  0.3560,  0.6730,  0.5913, -0.0406, -0.4354,\n",
       "         -0.0260, -1.0539,  0.5231,  0.1247, -0.4371, -0.6622,  0.7778, -0.8840,\n",
       "         -0.2181, -0.1497,  0.3358, -0.0389, -0.4206,  0.0149, -0.4003,  0.7932,\n",
       "          0.0479,  0.9210, -0.6174, -0.1602,  0.5868, -0.2327, -0.5462,  0.0469,\n",
       "          0.1909, -0.1520,  0.4297,  0.3800,  0.1515, -0.9824,  0.3965, -0.9540,\n",
       "         -0.0755,  0.2224,  0.1516, -0.2089, -0.9803, -0.3576,  0.9367,  0.6668,\n",
       "          0.3367, -0.4005, -0.9048,  0.2058, -0.5698,  0.1852, -0.7344,  0.1298,\n",
       "         -0.8448,  0.5389, -0.2520, -0.5603, -0.4626, -0.9710, -0.3208,  1.0662,\n",
       "         -0.8357, -0.6697,  0.3088, -0.6979,  0.1963, -0.3874, -0.8199,  1.2720,\n",
       "         -1.0240, -1.4884, -1.1532, -0.2577,  0.6485, -1.0620, -0.0264, -0.3599,\n",
       "          0.1311,  0.1389,  0.4760, -0.3228,  0.4372, -0.4965,  0.9095,  0.4633,\n",
       "          0.9172, -0.5252, -0.0584,  0.9295,  0.8998,  0.0175,  0.2446,  1.1882,\n",
       "         -0.6279, -0.3437,  1.1195,  0.3568,  0.3537,  0.1462,  0.2081,  1.1582,\n",
       "          0.3092, -0.3179,  0.7664,  0.6102,  0.1674, -0.1422,  1.1518,  0.6537,\n",
       "         -0.2685, -0.0644,  0.1604,  0.4406,  0.4447, -0.2458, -1.0252,  0.5056,\n",
       "          0.8270, -0.9240,  0.7616,  0.6924, -0.6102, -0.3138, -0.2375,  0.2714,\n",
       "         -0.1876,  0.4108,  0.0074, -0.6127,  0.4157, -0.4832,  0.3743,  0.9866,\n",
       "         -0.0093, -0.8833,  1.1153,  0.2869,  0.5494,  0.3767,  0.4559, -0.0358,\n",
       "         -0.8092, -0.9690,  0.1519, -0.0320,  0.5107, -0.2678,  0.6853, -0.2815,\n",
       "         -0.5650, -0.5011,  0.0288,  0.3662, -0.0366, -0.3084,  0.6960, -0.0043,\n",
       "          0.7872, -0.2501,  0.2809, -0.3660, -0.5080,  0.4735, -1.2954, -0.1043,\n",
       "         -0.6490, -0.1345,  0.3809, -0.5151, -0.1782, -0.2102,  0.4378, -0.0992,\n",
       "         -0.0979,  0.1750,  0.2519,  0.2976, -0.1512, -0.5954, -1.2565, -0.3029,\n",
       "          0.0878,  0.4517, -0.2450,  0.1537, -0.0685, -0.9713, -0.2456,  0.3376,\n",
       "         -0.4318, -0.1788,  0.2610, -1.0668, -0.6484, -1.1125,  0.7198,  0.2000,\n",
       "          0.8346, -0.1924,  0.4338, -0.2055, -1.4052, -0.4936,  0.1809, -0.3480,\n",
       "         -0.1159,  0.7199, -0.3907, -0.0892,  0.0771, -1.1005, -0.0453, -0.0578,\n",
       "         -0.2885, -0.6318,  1.2244,  0.0325,  0.4824,  0.2664, -0.3985, -0.7338,\n",
       "          0.5534,  0.4577,  0.0160, -0.7000, -0.7004, -0.8561,  0.5435, -1.0853,\n",
       "          0.7494,  0.1943, -0.6823,  0.3461,  0.3662, -1.0201,  0.1205,  0.2941,\n",
       "         -0.5521, -0.4193, -1.0569,  0.2005, -0.1173,  0.0091,  0.3690, -0.5224,\n",
       "          0.5320,  0.2906, -0.2228, -0.6415, -1.3495, -0.4105,  0.3813, -0.8285,\n",
       "          0.7133,  0.4146, -0.4008,  1.0825,  0.9929, -0.0729, -0.0507,  0.4528,\n",
       "          0.8253, -0.4392,  0.3602, -0.2899,  0.3553, -0.3980, -0.2744,  0.6376,\n",
       "          0.6097,  0.7820,  0.1112,  2.0085,  0.1256, -0.1191,  1.1015,  0.7532,\n",
       "         -0.0983, -0.1038,  0.2612, -0.5061,  1.2647,  0.4212, -0.9112, -0.5832,\n",
       "         -0.9354, -0.4649,  0.2428,  0.7392,  0.0200,  0.3089, -0.5559,  0.3631,\n",
       "         -0.2691,  0.0583,  0.5454,  0.7356,  0.7302, -0.1983,  0.0340, -0.7769]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vans_filt_[i] contains ((sentence_id, word, word_sense),(embedding))\n",
    "#sentence_id = sentence from original corpus which contains word, and the corresponding sense\n",
    "\n",
    "vans_filt_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______________________________________________\n",
    "\n",
    "### Loading embeddings for every model, layer and dataset\n",
    "\n",
    "You can use the previous example to load embeddings for every model, layer and dataset, one by one.\n",
    "\n",
    "Or, you can loop over each dataset, model and layer to get every embedding\n",
    "\n",
    "### models\n",
    "model_types = ['bert', 'gpt2', 'xlnet', 'electra']\n",
    "\n",
    "### datasets\n",
    "datasets = ['semeval15_13', 'senseval3task1', 'senseval2', 'semeval13_12', 'semeval07_7']\n",
    "\n",
    "\n",
    "***Don't run the following script before making suggested changes!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##suggested changes are in comments\n",
    "\n",
    "data = {}\n",
    "data_r = {}\n",
    "van = {}\n",
    "van_r = {}\n",
    "words = {}\n",
    "words_r = {}\n",
    "van_vec = {}\n",
    "van_vec_r = {}\n",
    "\n",
    "\n",
    "for model_type in model_types: ##currently set to get data for every model sequentially\n",
    "    for layer in range(13): ##currently set to get data for every model layer sequentially\n",
    "        for data_num in datasets: ##currently set to get data for every data set sequentially\n",
    "            data[data_num] = get_embs(data_num, layer, model_type)\n",
    "            van[data_num] = [((y[0][0], y[0][1], y[0][2]), y[1]) for x in data[data_num] for y in x]\n",
    "            van_vec[data_num] = [x[1] for x in van[data_num]]\n",
    "\n",
    "        ################### ORIGINAL EMBEDDINGS ###################\n",
    "\n",
    "        wfs_ = []\n",
    "        vans_ = []\n",
    "        for data_num in datasets:\n",
    "            vans_i = van[data_num]\n",
    "            vans_ = vans_ + vans_i\n",
    "            \n",
    "        \n",
    "        ##original embeddings for given configuration\n",
    "    \n",
    "        vans_filt_ = [x for x in vans_ if ((x[0][1] in [y1[0] for y1 in nouns]) or (x[0][1] in [y2[0] for y2 in verbs]) or\n",
    "                                     (x[0][1] in [y3[0] for y3 in adjectives]))]\n",
    "        \n",
    "        ################### RETROFITTED EMBEDDINGS ###################\n",
    "    \n",
    "        for data_num in datasets:\n",
    "            data_r[data_num] = get_retro_embs(data_num, layer, model_type, 1)\n",
    "            van_r[data_num] = [((x[0][0], x[0][1], x[0][2]), x[1]) for x in data_r[data_num]]\n",
    "            van_vec[data_num] = [x[1] for x in van_r[data_num]]\n",
    "\n",
    "        wfs_r_ = []\n",
    "        vans_r_ = []\n",
    "        for data_num in datasets:\n",
    "            vans_i_r = van_r[data_num]\n",
    "            vans_r_ = vans_r_ + vans_i_r\n",
    "        \n",
    "        ##retrofitted embeddings for given configuration\n",
    "        vans_filt_r_ = [x for x in vans_r_ if ((x[0][1] in [y1[0] for y1 in nouns]) or (x[0][1] in [y2[0] for y2 in verbs]) or\n",
    "                                     (x[0][1] in [y3[0] for y3 in adjectives]))]\n",
    "    \n",
    "        \n",
    "        ######## ADD CODE TO SAVE/USE/TRANSFER FILES TO ANOTHER DESTINATION ##########\n",
    "        ### files to be used; original embeddings: vans_filt_ ; retrofitted embeddings: vans_filt_r_ ###\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
